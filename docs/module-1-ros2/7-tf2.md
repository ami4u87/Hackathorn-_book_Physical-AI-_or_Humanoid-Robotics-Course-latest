# TF2 (Transform Library)

TF2 (Transform Library 2) is a package in ROS 2 that provides a framework for tracking coordinate frames in a robotic system over time. It allows you to transform points, vectors, and other data between different coordinate frames, which is essential for tasks like navigation, manipulation, and sensor fusion in robotics.

## Understanding Coordinate Frames and Transformations

In robotics, different sensors, actuators, and components operate in their own coordinate systems. For example:
- A camera has its own frame (typically with X pointing right, Y down, Z forward)
- A LiDAR sensor has its own frame
- The robot base has a frame
- Individual joints have their own frames

TF2 allows you to transform data between these different frames, enabling the robot to understand how all its components relate to each other spatially.

## Key Concepts

### Coordinate Frames
A coordinate frame is a system of axes used to represent positions and orientations. Each frame has:
- An origin (position)
- Orientation (rotation)
- A unique name

### Transformations
A transformation describes how to convert coordinates from one frame to another. It includes:
- Translation (x, y, z position)
- Rotation (orientation, typically represented as a quaternion)

### The Transform Tree
All frames in a system are connected in a tree structure with a single root frame. This prevents cycles and ensures that any frame can be transformed to any other frame through a series of transformations.

## TF2 in Practice

### Python TF2 Example

Let's create a simple example that demonstrates TF2 usage. First, create a new package:

```bash
cd ~/ros2_ws/src
ros2 pkg create --build-type ament_python py_tf2
```

Create a TF2 broadcaster at `src/py_tf2/py_tf2/turtle_tf2_broadcaster.py`:

```python
import math
import numpy as np
from geometry_msgs.msg import TransformStamped
import rclpy
from rclpy.node import Node
from tf2_ros import TransformBroadcaster
from vrx_gz.sim import World


class FramePublisher(Node):

    def __init__(self):
        super().__init__('frame_publisher')

        # Create a transform broadcaster
        self.tf_broadcaster = TransformBroadcaster(self)

        # Create a timer to publish transforms periodically
        self.timer = self.create_timer(0.1, self.publish_transform)

    def publish_transform(self):
        # Create a transform from 'world' to 'robot' frame
        t = TransformStamped()

        # Fill the header
        t.header.stamp = self.get_clock().now().to_msg()
        t.header.frame_id = 'world'
        t.child_frame_id = 'robot'

        # Define the transformation (example: robot moving in a circle)
        current_time = self.get_clock().now().nanoseconds / 1e9
        t.transform.translation.x = math.cos(current_time / 2.0) * 2.0
        t.transform.translation.y = math.sin(current_time / 2.0) * 2.0
        t.transform.translation.z = 0.0

        # Simple rotation (no rotation in this example)
        t.transform.rotation.x = 0.0
        t.transform.rotation.y = 0.0
        t.transform.rotation.z = 0.0
        t.transform.rotation.w = 1.0

        # Send the transformation
        self.tf_broadcaster.sendTransform(t)


def main(args=None):
    rclpy.init(args=args)
    node = FramePublisher()

    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
```

Now create a TF2 listener at `src/py_tf2/py_tf2/turtle_tf2_listener.py`:

```python
import math
import numpy as np
from geometry_msgs.msg import Twist
import rclpy
from rclpy.node import Node
from tf2_ros import TransformListener, Buffer
from tf2_ros import LookupException, ConnectivityException, ExtrapolationException


class FrameListener(Node):

    def __init__(self):
        super().__init__('frame_listener')

        # Create a transform buffer
        self.tf_buffer = Buffer()

        # Create a transform listener
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # Create a publisher for velocity commands
        self.publisher = self.create_publisher(Twist, 'turtle2/cmd_vel', 1)

        # Create a timer to check transforms periodically
        self.timer = self.create_timer(0.1, self.on_timer)

    def on_timer(self):
        # Look up the transform between 'world' and 'robot' frames
        try:
            t = self.tf_buffer.lookup_transform(
                'world',
                'robot',
                rclpy.time.Time())  # Use 0 for latest available transform
        except (LookupException, ConnectivityException, ExtrapolationException):
            self.get_logger().info('Transform not available')
            return

        # Calculate the desired velocity to follow the robot
        msg = Twist()
        msg.linear.x = 1.0  # Move forward at 1 m/s
        msg.angular.z = 1.0  # Rotate at 1 rad/s

        # Publish the velocity command
        self.publisher.publish(msg)

        # Log the transform information
        self.get_logger().info(
            f'Robot position: ({t.transform.translation.x:.2f}, '
            f'{t.transform.translation.y:.2f}, '
            f'{t.transform.translation.z:.2f})')


def main(args=None):
    rclpy.init(args=args)
    node = FrameListener()

    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
```

### Static Transform Publisher

For transformations that don't change over time (like the position of a sensor on a robot), you can use a static transform publisher:

```python
from geometry_msgs.msg import TransformStamped
from tf2_ros import StaticTransformBroadcaster
import rclpy
from rclpy.node import Node


class StaticFramePublisher(Node):

    def __init__(self):
        super().__init__('static_frame_publisher')

        # Create a static transform broadcaster
        self.tf_static_broadcaster = StaticTransformBroadcaster(self)

        # Publish the static transform
        self.publish_static_transform()

    def publish_static_transform(self):
        # Create a transform from 'robot_base' to 'laser' frame
        t = TransformStamped()

        t.header.stamp = self.get_clock().now().to_msg()
        t.header.frame_id = 'robot_base'
        t.child_frame_id = 'laser'

        # Set the static transform (sensor is 0.1m forward and 0.05m up from base)
        t.transform.translation.x = 0.1
        t.transform.translation.y = 0.0
        t.transform.translation.z = 0.05

        # No rotation (sensor aligned with base)
        t.transform.rotation.x = 0.0
        t.transform.rotation.y = 0.0
        t.transform.rotation.z = 0.0
        t.transform.rotation.w = 1.0

        self.tf_static_broadcaster.sendTransform(t)


def main(args=None):
    rclpy.init(args=args)
    node = StaticFramePublisher()

    try:
        # Keep the node alive for a short time to publish the static transform
        rclpy.spin_once(node, timeout_sec=1)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
```

## Using TF2 Command Line Tools

ROS 2 provides several command-line tools for working with TF2:

```bash
# View the transform tree
ros2 run tf2_tools view_frames

# Get a specific transform
ros2 run tf2_ros tf2_echo <source_frame> <target_frame>

# View all available transforms
ros2 run tf2_ros tf2_monitor

# Publish a static transform from command line
ros2 run tf2_ros static_transform_publisher x y z qx qy qz qw frame_id child_frame_id
```

## TF2 Data Types

TF2 works with various geometry message types:
- `PointStamped`: A point in space with a timestamp and frame
- `PoseStamped`: A position and orientation with timestamp and frame
- `Vector3Stamped`: A vector with timestamp and frame
- `TransformStamped`: A full transformation between two frames

## Best Practices

1. **Frame naming conventions**: Use descriptive, consistent names for frames. Common conventions include:
   - `base_link`: Robot's base frame
   - `camera_frame`: Camera's coordinate frame
   - `map`: World-fixed frame
   - `odom`: Odometry frame

2. **Transform tree design**: Design your transform tree carefully to avoid cycles and ensure all necessary transforms are available.

3. **Timing considerations**: Be aware of the timing of transforms, especially when working with moving robots.

4. **Static vs dynamic**: Use static transforms for fixed relationships (like sensor mounts) and dynamic transforms for moving parts.

5. **Error handling**: Always handle potential transform lookup failures gracefully.

6. **Performance**: For high-frequency applications, consider caching transforms when appropriate.

## Common Transformations

For humanoid robots, common transforms include:
- `base_link` to `left_foot` and `right_foot`
- `base_link` to `left_hand` and `right_hand`
- `base_link` to `head`
- Sensor frames (cameras, IMUs) relative to the robot base

## Integration with Physical AI

In the context of Physical AI and humanoid robotics, TF2 is crucial for:
- Sensor fusion: Combining data from multiple sensors
- Perception: Understanding object positions relative to the robot
- Planning: Calculating trajectories in the correct coordinate frame
- Control: Converting desired movements to joint commands

## Summary

TF2 is essential for any robotic system that needs to understand spatial relationships between different components. It provides the foundation for sensor fusion, navigation, manipulation, and perception tasks. Understanding how to properly set up and use TF2 transforms is crucial for developing effective robotic applications.

In the next section, we'll explore the exercises for Module 1, which will help reinforce the concepts learned in this module.