"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[601],{4286:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var i=o(4848),t=o(8453);const s={},a="Module 4: Vision-Language-Action",r={id:"module-4-vla/index",title:"Module 4: Vision-Language-Action",description:"This module introduces Vision-Language-Action (VLA) models for interpreting natural language commands and visual scenes, outputting high-level action plans for robotic systems.",source:"@site/docs/module-4-vla/index.md",sourceDirName:"module-4-vla",slug:"/module-4-vla/",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-4-vla/",draft:!1,unlisted:!1,editUrl:"https://github.com/ami4u87/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/tree/master/docs/module-4-vla/index.md",tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"Module 3 Exercises",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-3-perception/exercises"},next:{title:"GPT-4 Vision Integration",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-4-vla/gpt4-vision"}},l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2}];function u(e){const n={h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"module-4-vision-language-action",children:"Module 4: Vision-Language-Action"}),"\n",(0,i.jsx)(n.p,{children:"This module introduces Vision-Language-Action (VLA) models for interpreting natural language commands and visual scenes, outputting high-level action plans for robotic systems."}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Connect GPT-4 Vision to interpret natural language commands"}),"\n",(0,i.jsx)(n.li,{children:"Process camera images and text together"}),"\n",(0,i.jsx)(n.li,{children:"Generate structured action sequences"}),"\n",(0,i.jsx)(n.li,{children:"Validate action feasibility with planners"}),"\n",(0,i.jsx)(n.li,{children:"Handle ambiguous commands"}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>a,x:()=>r});var i=o(6540);const t={},s=i.createContext(t);function a(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);