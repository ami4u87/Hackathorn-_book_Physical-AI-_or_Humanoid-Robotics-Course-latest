"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[463],{886:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>m,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var t=r(4848),s=r(8453);const o={},a="TF2 (Transform Library)",i={id:"module-1-ros2/tf2",title:"TF2 (Transform Library)",description:"TF2 (Transform Library 2) is a package in ROS 2 that provides a framework for tracking coordinate frames in a robotic system over time. It allows you to transform points, vectors, and other data between different coordinate frames, which is essential for tasks like navigation, manipulation, and sensor fusion in robotics.",source:"@site/docs/module-1-ros2/7-tf2.md",sourceDirName:"module-1-ros2",slug:"/module-1-ros2/tf2",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-1-ros2/tf2",draft:!1,unlisted:!1,editUrl:"https://github.com/ami4u87/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/tree/master/docs/module-1-ros2/7-tf2.md",tags:[],version:"current",sidebarPosition:7,frontMatter:{},sidebar:"docsSidebar",previous:{title:"Launch Files",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-1-ros2/launch"},next:{title:"Module 1 Exercises",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-1-ros2/exercises"}},l={},c=[{value:"Understanding Coordinate Frames and Transformations",id:"understanding-coordinate-frames-and-transformations",level:2},{value:"Key Concepts",id:"key-concepts",level:2},{value:"Coordinate Frames",id:"coordinate-frames",level:3},{value:"Transformations",id:"transformations",level:3},{value:"The Transform Tree",id:"the-transform-tree",level:3},{value:"TF2 in Practice",id:"tf2-in-practice",level:2},{value:"Python TF2 Example",id:"python-tf2-example",level:3},{value:"Static Transform Publisher",id:"static-transform-publisher",level:3},{value:"Using TF2 Command Line Tools",id:"using-tf2-command-line-tools",level:2},{value:"TF2 Data Types",id:"tf2-data-types",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Common Transformations",id:"common-transformations",level:2},{value:"Integration with Physical AI",id:"integration-with-physical-ai",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"tf2-transform-library",children:"TF2 (Transform Library)"}),"\n",(0,t.jsx)(e.p,{children:"TF2 (Transform Library 2) is a package in ROS 2 that provides a framework for tracking coordinate frames in a robotic system over time. It allows you to transform points, vectors, and other data between different coordinate frames, which is essential for tasks like navigation, manipulation, and sensor fusion in robotics."}),"\n",(0,t.jsx)(e.h2,{id:"understanding-coordinate-frames-and-transformations",children:"Understanding Coordinate Frames and Transformations"}),"\n",(0,t.jsx)(e.p,{children:"In robotics, different sensors, actuators, and components operate in their own coordinate systems. For example:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"A camera has its own frame (typically with X pointing right, Y down, Z forward)"}),"\n",(0,t.jsx)(e.li,{children:"A LiDAR sensor has its own frame"}),"\n",(0,t.jsx)(e.li,{children:"The robot base has a frame"}),"\n",(0,t.jsx)(e.li,{children:"Individual joints have their own frames"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"TF2 allows you to transform data between these different frames, enabling the robot to understand how all its components relate to each other spatially."}),"\n",(0,t.jsx)(e.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,t.jsx)(e.h3,{id:"coordinate-frames",children:"Coordinate Frames"}),"\n",(0,t.jsx)(e.p,{children:"A coordinate frame is a system of axes used to represent positions and orientations. Each frame has:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"An origin (position)"}),"\n",(0,t.jsx)(e.li,{children:"Orientation (rotation)"}),"\n",(0,t.jsx)(e.li,{children:"A unique name"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"transformations",children:"Transformations"}),"\n",(0,t.jsx)(e.p,{children:"A transformation describes how to convert coordinates from one frame to another. It includes:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Translation (x, y, z position)"}),"\n",(0,t.jsx)(e.li,{children:"Rotation (orientation, typically represented as a quaternion)"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"the-transform-tree",children:"The Transform Tree"}),"\n",(0,t.jsx)(e.p,{children:"All frames in a system are connected in a tree structure with a single root frame. This prevents cycles and ensures that any frame can be transformed to any other frame through a series of transformations."}),"\n",(0,t.jsx)(e.h2,{id:"tf2-in-practice",children:"TF2 in Practice"}),"\n",(0,t.jsx)(e.h3,{id:"python-tf2-example",children:"Python TF2 Example"}),"\n",(0,t.jsx)(e.p,{children:"Let's create a simple example that demonstrates TF2 usage. First, create a new package:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python py_tf2\n"})}),"\n",(0,t.jsxs)(e.p,{children:["Create a TF2 broadcaster at ",(0,t.jsx)(e.code,{children:"src/py_tf2/py_tf2/turtle_tf2_broadcaster.py"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import math\nimport numpy as np\nfrom geometry_msgs.msg import TransformStamped\nimport rclpy\nfrom rclpy.node import Node\nfrom tf2_ros import TransformBroadcaster\nfrom vrx_gz.sim import World\n\n\nclass FramePublisher(Node):\n\n    def __init__(self):\n        super().__init__('frame_publisher')\n\n        # Create a transform broadcaster\n        self.tf_broadcaster = TransformBroadcaster(self)\n\n        # Create a timer to publish transforms periodically\n        self.timer = self.create_timer(0.1, self.publish_transform)\n\n    def publish_transform(self):\n        # Create a transform from 'world' to 'robot' frame\n        t = TransformStamped()\n\n        # Fill the header\n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = 'world'\n        t.child_frame_id = 'robot'\n\n        # Define the transformation (example: robot moving in a circle)\n        current_time = self.get_clock().now().nanoseconds / 1e9\n        t.transform.translation.x = math.cos(current_time / 2.0) * 2.0\n        t.transform.translation.y = math.sin(current_time / 2.0) * 2.0\n        t.transform.translation.z = 0.0\n\n        # Simple rotation (no rotation in this example)\n        t.transform.rotation.x = 0.0\n        t.transform.rotation.y = 0.0\n        t.transform.rotation.z = 0.0\n        t.transform.rotation.w = 1.0\n\n        # Send the transformation\n        self.tf_broadcaster.sendTransform(t)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = FramePublisher()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsxs)(e.p,{children:["Now create a TF2 listener at ",(0,t.jsx)(e.code,{children:"src/py_tf2/py_tf2/turtle_tf2_listener.py"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import math\nimport numpy as np\nfrom geometry_msgs.msg import Twist\nimport rclpy\nfrom rclpy.node import Node\nfrom tf2_ros import TransformListener, Buffer\nfrom tf2_ros import LookupException, ConnectivityException, ExtrapolationException\n\n\nclass FrameListener(Node):\n\n    def __init__(self):\n        super().__init__('frame_listener')\n\n        # Create a transform buffer\n        self.tf_buffer = Buffer()\n\n        # Create a transform listener\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Create a publisher for velocity commands\n        self.publisher = self.create_publisher(Twist, 'turtle2/cmd_vel', 1)\n\n        # Create a timer to check transforms periodically\n        self.timer = self.create_timer(0.1, self.on_timer)\n\n    def on_timer(self):\n        # Look up the transform between 'world' and 'robot' frames\n        try:\n            t = self.tf_buffer.lookup_transform(\n                'world',\n                'robot',\n                rclpy.time.Time())  # Use 0 for latest available transform\n        except (LookupException, ConnectivityException, ExtrapolationException):\n            self.get_logger().info('Transform not available')\n            return\n\n        # Calculate the desired velocity to follow the robot\n        msg = Twist()\n        msg.linear.x = 1.0  # Move forward at 1 m/s\n        msg.angular.z = 1.0  # Rotate at 1 rad/s\n\n        # Publish the velocity command\n        self.publisher.publish(msg)\n\n        # Log the transform information\n        self.get_logger().info(\n            f'Robot position: ({t.transform.translation.x:.2f}, '\n            f'{t.transform.translation.y:.2f}, '\n            f'{t.transform.translation.z:.2f})')\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = FrameListener()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h3,{id:"static-transform-publisher",children:"Static Transform Publisher"}),"\n",(0,t.jsx)(e.p,{children:"For transformations that don't change over time (like the position of a sensor on a robot), you can use a static transform publisher:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"from geometry_msgs.msg import TransformStamped\nfrom tf2_ros import StaticTransformBroadcaster\nimport rclpy\nfrom rclpy.node import Node\n\n\nclass StaticFramePublisher(Node):\n\n    def __init__(self):\n        super().__init__('static_frame_publisher')\n\n        # Create a static transform broadcaster\n        self.tf_static_broadcaster = StaticTransformBroadcaster(self)\n\n        # Publish the static transform\n        self.publish_static_transform()\n\n    def publish_static_transform(self):\n        # Create a transform from 'robot_base' to 'laser' frame\n        t = TransformStamped()\n\n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = 'robot_base'\n        t.child_frame_id = 'laser'\n\n        # Set the static transform (sensor is 0.1m forward and 0.05m up from base)\n        t.transform.translation.x = 0.1\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 0.05\n\n        # No rotation (sensor aligned with base)\n        t.transform.rotation.x = 0.0\n        t.transform.rotation.y = 0.0\n        t.transform.rotation.z = 0.0\n        t.transform.rotation.w = 1.0\n\n        self.tf_static_broadcaster.sendTransform(t)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = StaticFramePublisher()\n\n    try:\n        # Keep the node alive for a short time to publish the static transform\n        rclpy.spin_once(node, timeout_sec=1)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsx)(e.h2,{id:"using-tf2-command-line-tools",children:"Using TF2 Command Line Tools"}),"\n",(0,t.jsx)(e.p,{children:"ROS 2 provides several command-line tools for working with TF2:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# View the transform tree\nros2 run tf2_tools view_frames\n\n# Get a specific transform\nros2 run tf2_ros tf2_echo <source_frame> <target_frame>\n\n# View all available transforms\nros2 run tf2_ros tf2_monitor\n\n# Publish a static transform from command line\nros2 run tf2_ros static_transform_publisher x y z qx qy qz qw frame_id child_frame_id\n"})}),"\n",(0,t.jsx)(e.h2,{id:"tf2-data-types",children:"TF2 Data Types"}),"\n",(0,t.jsx)(e.p,{children:"TF2 works with various geometry message types:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"PointStamped"}),": A point in space with a timestamp and frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"PoseStamped"}),": A position and orientation with timestamp and frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"Vector3Stamped"}),": A vector with timestamp and frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"TransformStamped"}),": A full transformation between two frames"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Frame naming conventions"}),": Use descriptive, consistent names for frames. Common conventions include:"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"base_link"}),": Robot's base frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"camera_frame"}),": Camera's coordinate frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"map"}),": World-fixed frame"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"odom"}),": Odometry frame"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Transform tree design"}),": Design your transform tree carefully to avoid cycles and ensure all necessary transforms are available."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Timing considerations"}),": Be aware of the timing of transforms, especially when working with moving robots."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Static vs dynamic"}),": Use static transforms for fixed relationships (like sensor mounts) and dynamic transforms for moving parts."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Error handling"}),": Always handle potential transform lookup failures gracefully."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Performance"}),": For high-frequency applications, consider caching transforms when appropriate."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"common-transformations",children:"Common Transformations"}),"\n",(0,t.jsx)(e.p,{children:"For humanoid robots, common transforms include:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"base_link"})," to ",(0,t.jsx)(e.code,{children:"left_foot"})," and ",(0,t.jsx)(e.code,{children:"right_foot"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"base_link"})," to ",(0,t.jsx)(e.code,{children:"left_hand"})," and ",(0,t.jsx)(e.code,{children:"right_hand"})]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"base_link"})," to ",(0,t.jsx)(e.code,{children:"head"})]}),"\n",(0,t.jsx)(e.li,{children:"Sensor frames (cameras, IMUs) relative to the robot base"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"integration-with-physical-ai",children:"Integration with Physical AI"}),"\n",(0,t.jsx)(e.p,{children:"In the context of Physical AI and humanoid robotics, TF2 is crucial for:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Sensor fusion: Combining data from multiple sensors"}),"\n",(0,t.jsx)(e.li,{children:"Perception: Understanding object positions relative to the robot"}),"\n",(0,t.jsx)(e.li,{children:"Planning: Calculating trajectories in the correct coordinate frame"}),"\n",(0,t.jsx)(e.li,{children:"Control: Converting desired movements to joint commands"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"TF2 is essential for any robotic system that needs to understand spatial relationships between different components. It provides the foundation for sensor fusion, navigation, manipulation, and perception tasks. Understanding how to properly set up and use TF2 transforms is crucial for developing effective robotic applications."}),"\n",(0,t.jsx)(e.p,{children:"In the next section, we'll explore the exercises for Module 1, which will help reinforce the concepts learned in this module."})]})}function m(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,r)=>{r.d(e,{R:()=>a,x:()=>i});var t=r(6540);const s={},o=t.createContext(s);function a(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);