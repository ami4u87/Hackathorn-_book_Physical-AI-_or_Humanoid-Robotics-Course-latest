"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[997],{5649:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var a=t(4848),i=t(8453);const s={},r="Structured Action Generation",o={id:"module-4-vla/action-sequences",title:"Structured Action Generation",description:"Generate executable robot action sequences from high-level commands.",source:"@site/docs/module-4-vla/3-action-sequences.md",sourceDirName:"module-4-vla",slug:"/module-4-vla/action-sequences",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-4-vla/action-sequences",draft:!1,unlisted:!1,editUrl:"https://github.com/ami4u87/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/tree/master/docs/module-4-vla/3-action-sequences.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{},sidebar:"docsSidebar",previous:{title:"Multi-Modal Processing",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-4-vla/multimodal"},next:{title:"Action Feasibility Validation",permalink:"/Hackathorn-_book_Physical-AI-_or_Humanoid-Robotics-Course-latest/docs/module-4-vla/validation"}},c={},l=[{value:"Action Primitives",id:"action-primitives",level:2},{value:"Structured Generation",id:"structured-generation",level:2},{value:"Hierarchical Planning",id:"hierarchical-planning",level:2},{value:"Action Libraries",id:"action-libraries",level:2},{value:"Further Reading",id:"further-reading",level:2}];function p(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.h1,{id:"structured-action-generation",children:"Structured Action Generation"}),"\n",(0,a.jsx)(e.p,{children:"Generate executable robot action sequences from high-level commands."}),"\n",(0,a.jsx)(e.h2,{id:"action-primitives",children:"Action Primitives"}),"\n",(0,a.jsx)(e.p,{children:"Define basic robot capabilities:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'from dataclasses import dataclass\nfrom typing import List, Tuple, Optional\n\n@dataclass\nclass RobotAction:\n    action_type: str\n    parameters: dict\n    preconditions: List[str] = None\n    postconditions: List[str] = None\n\n# Define action types\nACTION_TYPES = {\n    "grasp": {\n        "params": ["object_id", "grasp_pose"],\n        "duration": 2.0\n    },\n    "place": {\n        "params": ["object_id", "target_pose"],\n        "duration": 2.0\n    },\n    "move_to": {\n        "params": ["target_pose"],\n        "duration": 3.0\n    },\n    "open_gripper": {\n        "params": [],\n        "duration": 1.0\n    },\n    "close_gripper": {\n        "params": [],\n        "duration": 1.0\n    },\n    "rotate": {\n        "params": ["axis", "angle"],\n        "duration": 1.5\n    }\n}\n'})}),"\n",(0,a.jsx)(e.h2,{id:"structured-generation",children:"Structured Generation"}),"\n",(0,a.jsx)(e.p,{children:"Use JSON schemas for consistent outputs."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def get_action_schema():\n    """Define JSON schema for action sequences"""\n    return {\n        "type": "object",\n        "properties": {\n            "task_understanding": {\n                "type": "string",\n                "description": "Brief description of understood task"\n            },\n            "action_sequence": {\n                "type": "array",\n                "items": {\n                    "type": "object",\n                    "properties": {\n                        "step": {"type": "integer"},\n                        "action_type": {\n                            "type": "string",\n                            "enum": list(ACTION_TYPES.keys())\n                        },\n                        "parameters": {\n                            "type": "object"\n                        },\n                        "reasoning": {\n                            "type": "string",\n                            "description": "Why this action is needed"\n                        }\n                    },\n                    "required": ["step", "action_type", "parameters"]\n                }\n            },\n            "estimated_duration": {\n                "type": "number",\n                "description": "Total estimated time in seconds"\n            }\n        },\n        "required": ["task_understanding", "action_sequence"]\n    }\n\nclass ActionSequenceGenerator:\n    def __init__(self, vla_client):\n        self.vla = vla_client\n        self.action_schema = get_action_schema()\n\n    def generate_sequence(self, image, command, constraints=None):\n        """\n        Generate structured action sequence\n\n        Args:\n            image: Scene image\n            command: Natural language command\n            constraints: Optional constraints (e.g., max_duration, forbidden_objects)\n\n        Returns:\n            Structured action sequence\n        """\n        # Build prompt\n        prompt = self.build_generation_prompt(command, constraints)\n\n        # Encode image\n        image_base64 = self.vla.encode_image(image)\n\n        # Generate with function calling\n        response = self.vla.client.chat.completions.create(\n            model="gpt-4-vision-preview",\n            messages=[\n                {\n                    "role": "system",\n                    "content": "You are a robot task planner. Generate structured, executable action sequences."\n                },\n                {\n                    "role": "user",\n                    "content": [\n                        {"type": "text", "text": prompt},\n                        {\n                            "type": "image_url",\n                            "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}\n                        }\n                    ]\n                }\n            ],\n            response_format={"type": "json_object"}\n        )\n\n        # Parse result\n        result = json.loads(response.choices[0].message.content)\n\n        # Validate\n        self.validate_sequence(result)\n\n        return result\n\n    def build_generation_prompt(self, command, constraints):\n        """Build detailed prompt for action generation"""\n        prompt = f"""\n        Generate a robot action sequence for: "{command}"\n\n        Available actions:\n        {json.dumps(ACTION_TYPES, indent=2)}\n\n        Constraints:\n        {json.dumps(constraints, indent=2) if constraints else "None"}\n\n        Provide response as JSON following this structure:\n        {{\n            "task_understanding": "...",\n            "action_sequence": [\n                {{\n                    "step": 1,\n                    "action_type": "move_to",\n                    "parameters": {{"target_pose": [x, y, z]}},\n                    "reasoning": "..."\n                }},\n                ...\n            ],\n            "estimated_duration": 10.5\n        }}\n        """\n        return prompt\n\n    def validate_sequence(self, sequence):\n        """Validate generated sequence"""\n        assert "action_sequence" in sequence, "Missing action_sequence"\n\n        for action in sequence["action_sequence"]:\n            action_type = action["action_type"]\n            assert action_type in ACTION_TYPES, f"Unknown action: {action_type}"\n\n            # Validate parameters\n            required_params = ACTION_TYPES[action_type]["params"]\n            for param in required_params:\n                assert param in action["parameters"], f"Missing parameter: {param}"\n'})}),"\n",(0,a.jsx)(e.h2,{id:"hierarchical-planning",children:"Hierarchical Planning"}),"\n",(0,a.jsx)(e.p,{children:"Break complex tasks into subtasks."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def hierarchical_plan(vla, image, high_level_goal):\n    """\n    Generate hierarchical plan\n\n    Returns:\n        {\n            "goal": "...",\n            "subtasks": [\n                {\n                    "subtask": "...",\n                    "actions": [...]\n                },\n                ...\n            ]\n        }\n    """\n    prompt = f"""\n    Break down this goal into subtasks: "{high_level_goal}"\n\n    For each subtask, provide:\n    1. Subtask description\n    2. Action sequence\n    3. Success criteria\n\n    Format as hierarchical JSON.\n    """\n\n    # Generate\n    # ... (similar to previous examples)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"action-libraries",children:"Action Libraries"}),"\n",(0,a.jsx)(e.p,{children:"Reusable action templates."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'ACTION_LIBRARY = {\n    "pick_and_place": {\n        "template": [\n            {"action_type": "move_to", "parameters": {"target": "{{object_location}}"}},\n            {"action_type": "open_gripper"},\n            {"action_type": "grasp", "parameters": {"object_id": "{{object_id}}"}},\n            {"action_type": "close_gripper"},\n            {"action_type": "move_to", "parameters": {"target": "{{place_location}}"}},\n            {"action_type": "open_gripper"}\n        ]\n    },\n    "inspect_object": {\n        "template": [\n            {"action_type": "move_to", "parameters": {"target": "{{object_location}}"}},\n            {"action_type": "rotate", "parameters": {"axis": "z", "angle": 360}},\n        ]\n    }\n}\n\ndef instantiate_template(template_name, **kwargs):\n    """Fill template with actual values"""\n    template = ACTION_LIBRARY[template_name]["template"]\n\n    # Replace placeholders\n    instantiated = []\n    for action in template:\n        action_copy = json.loads(json.dumps(action))  # Deep copy\n\n        # Replace in parameters\n        for key, value in action_copy["parameters"].items():\n            if isinstance(value, str) and value.startswith("{{"):\n                param_name = value.strip("{}")\n                action_copy["parameters"][key] = kwargs[param_name]\n\n        instantiated.append(action_copy)\n\n    return instantiated\n'})}),"\n",(0,a.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://arxiv.org/abs/2010.01083",children:"Task and Motion Planning"})}),"\n",(0,a.jsx)(e.li,{children:(0,a.jsx)(e.a,{href:"https://arxiv.org/abs/2305.14992",children:"LLM Planning"})}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(p,{...n})}):p(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>r,x:()=>o});var a=t(6540);const i={},s=a.createContext(i);function r(n){const e=a.useContext(s);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:r(n.components),a.createElement(s.Provider,{value:e},n.children)}}}]);